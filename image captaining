import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Dropout
from tensorflow.keras.models import load_model
from PIL import Image

# Load the pre-trained InceptionV3 model and define it as the encoder
def load_image_model():
    inception = InceptionV3(weights='imagenet')
    model = Model(inception.input, inception.layers[-2].output)
    return model

# Preprocess the image for InceptionV3
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(299, 299))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

# Extract image features using the InceptionV3 encoder
def extract_features(img_path, model):
    img = preprocess_image(img_path)
    features = model.predict(img)
    features = np.reshape(features, features.shape[1])
    return features

# Decoder model (pre-trained or fine-tuned LSTM model)
def load_caption_model():
    # Assuming you have a pre-trained model for captioning.
    # You can replace this with your own custom model.
    return load_model('caption_model.h5')

# Generate a caption from the trained model and extracted image features
def generate_caption(model, tokenizer, photo_features, max_length):
    in_text = 'startseq'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        yhat = model.predict([photo_features, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = tokenizer.index_word.get(yhat, None)
        if word is None:
            break
        in_text += ' ' + word
        if word == 'endseq':
            break
    return in_text

# Main function to caption an image
def caption_image(img_path, tokenizer, max_length):
    image_model = load_image_model()
    caption_model = load_caption_model()

    # Extract image features
    photo_features
